{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f223c3-125a-4da4-accb-d22d980ffe1f",
   "metadata": {},
   "source": [
    "# Goodreads Book Reviews Analysis - Numerical Data Exploration\n",
    "\n",
    "## Project Overview\n",
    "This project aims to analyze **Goodreads book reviews**, focusing on **1-star ratings** to understand patterns in harsh reviews. The analysis is divided into two parts:\n",
    "1. **Numerical Data Analysis** (Current Stage) - Examining numerical factors such as star ratings, review counts, and genre distributions.\n",
    "2. **Natural Language Processing (NLP) Analysis** (Next Stage) - Exploring book descriptions and text reviews to identify sentiment patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a057dee-934a-49ef-813a-0f63b2e77875",
   "metadata": {},
   "source": [
    "## Adding dataset with text reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefa3ac-fb9e-4c05-9fff-cf7cd8d38fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "chunk_size= 10000\n",
    "chunks= []\n",
    "\n",
    "with gzip.open (\"./Data/goodreads_reviews_dedup.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f): #read line by line\n",
    "        chunks.append(json.loads(line)) #convert json to stionf dict\n",
    "\n",
    "    #every chuck line, process data to write csv\n",
    "        if (i + 1) % chunk_size == 0:\n",
    "            df_chunk = pd.DataFrame(chunks)\n",
    "            df_chunk.to_csv(\"goodreads_reviews\", mode=\"a\", index= False, header = (i < chunk_size))\n",
    "            chunks = []\n",
    "        \n",
    "if chunks:\n",
    "    df_chunk = pd.DataFrame(chunks)\n",
    "    df_chunk.to_csv(\"goodreads_reviews\", mode =\"a\", index=False, header=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81556b3f-fcb7-4c51-804a-6a5d7125a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"goodreads_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea58185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7684f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['book_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "chunk_size= 10000\n",
    "chunks= []\n",
    "\n",
    "with gzip.open (\"./Data/goodreads_books.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f): #read line by line\n",
    "        chunks.append(json.loads(line)) #convert json to stionf dict\n",
    "         \n",
    "    #every chuck line, process data to write csv\n",
    "        if (i + 1) % chunk_size == 0:\n",
    "            df_chunk = pd.DataFrame(chunks)\n",
    "            df_chunk.to_csv(\"goodreads_books\", mode=\"a\", index= False, header = (i < chunk_size))\n",
    "            chunks = []\n",
    "        \n",
    "if chunks:\n",
    "    df_chunk = pd.DataFrame(chunks)\n",
    "    df_chunk.to_csv(\"goodreads_books\", mode =\"a\", index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv(\"goodreads_books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04077ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_books.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_reviews.merge(df_books, on=\"book_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d71781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ababa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_merged.drop(columns=['user_id','date_added','read_at','started_at','date_updated','read_at','kindle_asin','work_id','n_comments','asin','similar_books','series','similar_books','publication_month','publication_day','edition_information','is_ebook'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32876e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_merged.drop(columns=['format', 'num_pages', 'isbn13', 'link', 'title_without_series'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['review_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0573a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_merged['text_reviews_count']== 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['text_reviews_count'] == 0]\n",
    "#?? maybe outdated text review count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['rating'] == 0]\n",
    "#reviews that have text but no star rating was left? I am choosing to leave these out of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged= df_merged[df_merged['rating'].notna() & (df_merged['rating'] !=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this analysis I will only be focusing on english reviews\n",
    "#removing nonenglish rows and rows with no text in review_text or description. I dont think this will hurt bc the df is so large\n",
    "df_merged= df_merged.dropna(subset=['review_text','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning popular shelves column\n",
    "print(df_merged['popular_shelves'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2854c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing which shelves have the highest counts\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "#function that extracts shelf names from string lists of the shelf dictionaires\n",
    "def shelf_names(shelves_str):\n",
    "    shelves_list = ast.literal_eval(shelves_str) #convert the string to a list of dicts\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [shelf['name'] for shelf in shelves_list if 'name' in shelf] #extract 'name' value from each dict if it exists\n",
    "    return []\n",
    "\n",
    "shelf_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a68bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very large operation (takes about 100 minutes to run)\n",
    "for row in df_merged['popular_shelves'].dropna():\n",
    "    shelf_counter.update(shelf_names(row))\n",
    "\n",
    "print(shelf_counter.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc354730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "unique_shelves = list(shelf_counter.keys())\n",
    "print(f\"unique names: {len(unique_shelves)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63488b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shelf_counter.most_common(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_shelf(name):\n",
    "    return name.strip().lower().replace(\" \", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering shelf names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the author column\n",
    "print(df_merged['authors'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is already a language code column but it's not through. Try lang detect to fill in missing\n",
    "from langdetect import detect\n",
    "df_merged['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for final cleaning steps to slim down dataset futher before splitting  then saving to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9805d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split df into managable chunks for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for star in range(0,6):\n",
    "    df_star = df_merged[df_merged['rating'] == star]\n",
    "    df_star.to_csv(f\"{star}star_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "csv_files = [\"./Data/1star_reviews.csv\"]\n",
    "\n",
    "zip_path = \"./Data/1star_reviews.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file in csv_files:\n",
    "        arcname = os.path.basename(file)\n",
    "        zipf.write(file,arcname=arcname)\n",
    "\n",
    "zip_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning them to variables then checking size\n",
    "\n",
    "df_5star = pd.read_csv(\"./Data/5star_reviews.csv\")\n",
    "df_5star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6858eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4star = pd.read_csv(\"./Data/4star_reviews.csv\")\n",
    "df_4star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3star = pd.read_csv(\"./Data/3star_reviews.csv\")\n",
    "df_3star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2star = pd.read_csv(\"./Data/2star_reviews.csv\")\n",
    "df_2star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15225c65-a2b0-4325-8cc0-777fbf594670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba3d3b-a071-4b09-8c1a-28aceec7c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da14e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 419874 entries, 0 to 419873\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Unnamed: 0          419874 non-null  int64  \n",
      " 1   book_id             419874 non-null  int64  \n",
      " 2   review_id           419874 non-null  object \n",
      " 3   rating              419874 non-null  int64  \n",
      " 4   review_text         419874 non-null  object \n",
      " 5   n_votes             419874 non-null  int64  \n",
      " 6   isbn                328665 non-null  object \n",
      " 7   text_reviews_count  419874 non-null  float64\n",
      " 8   country_code        419874 non-null  object \n",
      " 9   language_code       340979 non-null  object \n",
      " 10  popular_shelves     419874 non-null  object \n",
      " 11  average_rating      419874 non-null  float64\n",
      " 12  description         419874 non-null  object \n",
      " 13  authors             419874 non-null  object \n",
      " 14  publisher           347484 non-null  object \n",
      " 15  publication_year    358879 non-null  float64\n",
      " 16  url                 419874 non-null  object \n",
      " 17  image_url           419874 non-null  object \n",
      " 18  ratings_count       419874 non-null  float64\n",
      " 19  title               419874 non-null  object \n",
      "dtypes: float64(4), int64(4), object(12)\n",
      "memory usage: 64.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1star = pd.read_csv(\"./1star_reviews.csv\")\n",
    "df_1star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20429fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample of the smallest rating dataset to test for cleaning\n",
    "sample_1star= df_1star.sample(10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning popular shelves column\n",
    "print(sample_1star['popular_shelves'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c2e5fd-ac8c-4af7-9114-6c37f5b4bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing which shelves have the highest counts\n",
    "#function that extracts shelf names from string lists of the shelf dictionaires\n",
    "def shelf_names(shelves_str):\n",
    "    shelves_list = ast.literal_eval(shelves_str) #convert the string to a list of dicts\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [shelf['name'] for shelf in shelves_list if 'name' in shelf] #extract 'name' value from each dict if it exists\n",
    "    return []\n",
    "\n",
    "shelf_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c09e7d9-5d99-4472-a69b-f81dc13cd3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to-read', 9929), ('currently-reading', 9297), ('owned', 8457), ('fiction', 8311), ('favorites', 8263), ('books-i-own', 7961), ('kindle', 7382), ('ebook', 7213), ('library', 7085), ('owned-books', 6950), ('to-buy', 6593), ('ebooks', 6318), ('wish-list', 5941), ('default', 5726), ('contemporary', 5486), ('my-books', 5381), ('audiobook', 5368), ('adult', 5238), ('romance', 5224), ('audiobooks', 5077), ('i-own', 4903), ('my-library', 4853), ('did-not-finish', 4748), ('dnf', 4737), ('audio', 4647), ('abandoned', 4567), ('favourites', 4412), ('e-book', 4404), ('series', 4208), ('novels', 4206), ('read-in-2015', 4022), ('own-it', 3976), ('books', 3873), ('book-club', 3829), ('fantasy', 3827), ('e-books', 3779), ('read-in-2016', 3764), ('read-in-2014', 3740), ('adult-fiction', 3735), ('maybe', 3717), ('young-adult', 3559), ('read-in-2013', 3381), ('read-in-2017', 3149), ('mystery', 3113), ('have', 3004), ('novel', 2992), ('reviewed', 2966), ('borrowed', 2906), ('ya', 2884), ('audible', 2854), ('audio-books', 2814), ('drama', 2801), ('english', 2660), ('read-in-2012', 2643), ('didn-t-finish', 2622), ('favorite', 2553), ('tbr', 2548), ('unfinished', 2525), ('contemporary-fiction', 2495), ('audio-book', 2459)]\n"
     ]
    }
   ],
   "source": [
    "#very large operation (takes about 100 minutes to run)\n",
    "for row in sample_1star['popular_shelves'].dropna():\n",
    "    shelf_counter.update(shelf_names(row))\n",
    "\n",
    "print(shelf_counter.most_common(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555e180-aa46-47bb-988e-f208abdee56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "unique_shelves = list(shelf_counter.keys())\n",
    "print(f\"unique names: {len(unique_shelves)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e450a1f3-f581-4c1b-a92d-2d67f58cc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "blacklist = {\n",
    "    'reading_status': [\n",
    "        'read', 'currently reading', 'dnf', 'unread', 'tbr', 'reread', 'finished', 'finish'\n",
    "    ],\n",
    "    'ownership': [\n",
    "        'owned', 'own', 'buy', 'bought', 'borrow', 'library', 'kindle', 'ebook', 'epub', \n",
    "        'paperback', 'nook', 'hardcover', 'download', 'ibooks', 'kobo', 'scribd'\n",
    "    ],\n",
    "    'rating_review': [\n",
    "        'star', 'favorite', 'favourite', 'review', 'recommend', 'amazing', 'must', \n",
    "        'best', 'loved', 'meh'\n",
    "    ],\n",
    "    'promotion_format': [\n",
    "        'audiobook', 'audio', 'netgalley', 'gift', 'challenge', 'award', 'edition', \n",
    "        'collection', 'release', 'published', 'sequel', 'shelve', 'scan', 'pdf', 'giveaway'\n",
    "    ],\n",
    "    'proper_nouns': [\n",
    "        'neal', 'stephenson', 'amy', 'kate', 'robert', 'emily', 'veronica', 'june', 'sophia', 'palmer', 'sarah'\n",
    "    ],\n",
    "    'misc': [\n",
    "        'storage', 'location', 'page', 'purchase', 'bore', 'new', 'hold', 'mine', \n",
    "        'drop', 'theme', 'funny', 'didnt', 'purchased', 'print', 'amazon', 'first',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Flatten into a set of lowercase blacklist words\n",
    "blacklist_set = set()\n",
    "for group in blacklist.values():\n",
    "    blacklist_set.update(word.lower() for word in group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df654cbe-e6d5-473d-aa7c-10dc5a9bbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def clean_name(name):\n",
    "    return name.lower().replace('-', ' ').replace('_', ' ').strip()\n",
    "\n",
    "def extract_shelves(shelves_str):\n",
    "    try:\n",
    "        shelves_list = ast.literal_eval(shelves_str)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [(clean_name(shelf['name']), int(shelf.get('count', 0)))\n",
    "                for shelf in shelves_list if 'name' in shelf]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09fb4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_mapping = {\n",
    "    'cowboys': 'cowboy',\n",
    "    'chick lit': 'chick lit',\n",
    "    'adult fiction': 'adult fiction',\n",
    "    'cowboy western': 'cowboy western',\n",
    "    'genre western': 'western',\n",
    "    'romantic suspense': 'romantic suspense',\n",
    "    'action': 'action',\n",
    "    'series romance': 'romance',\n",
    "    'genre romance': 'romance',\n",
    "    'romance modern': 'modern romance',\n",
    "    'science fiction': 'science fiction',\n",
    "    'sci fi': 'science fiction',\n",
    "    'scifi': 'science fiction',\n",
    "    'post apocalyptic': 'post apocalyptic',\n",
    "    'sf': 'science fiction',\n",
    "    'sci fi fantasy': 'science fiction fantasy',\n",
    "    'dystopia': 'dystopian',\n",
    "    'apocalyptic': 'apocalyptic',\n",
    "    'science': 'science',\n",
    "    'speculative fiction': 'speculative fiction',\n",
    "    'fantasy sci fi': 'science fiction fantasy',\n",
    "    'apocalypse': 'apocalyptic',\n",
    "    'space opera': 'space opera',\n",
    "    'science fiction fantasy': 'science fiction fantasy',\n",
    "    'hard sci fi': 'hard science fiction',\n",
    "    'sff': 'science fiction fantasy',\n",
    "    'post apocalypse': 'post apocalyptic',\n",
    "    'sf fantasy': 'science fiction fantasy',\n",
    "    'sci fi and fantasy': 'science fiction fantasy',\n",
    "    'hard scifi': 'hard science fiction',\n",
    "    'sciencefiction': 'science fiction',\n",
    "    'regency romance': 'regency romance',\n",
    "    'romance historical': 'historical romance',\n",
    "    'mf': 'm f',\n",
    "    'historical romances': 'historical romance',\n",
    "    'historicals': 'historical',\n",
    "    'humorous': 'humor',\n",
    "    'humour': 'humor',\n",
    "    'humour comedy': 'humor',\n",
    "    'young adult': 'young adult',\n",
    "    'ya': 'young adult',\n",
    "    'fairies': 'fairies',\n",
    "    'faeries': 'fairies',\n",
    "    'faerie': 'fairies',\n",
    "    'fey': 'fae',\n",
    "    'ya fantasy': 'young adult fantasy',\n",
    "    'paranormal romance': 'paranormal romance',\n",
    "    'historical fantasy': 'historical fantasy',\n",
    "    'historical fic': 'historical fiction',\n",
    "    'supernatural': 'supernatural',\n",
    "    'faries': 'fairies',\n",
    "    'classic lit': 'classic literature',\n",
    "    'british lit': 'british literature',\n",
    "    'brit lit': 'british literature',\n",
    "    'english lit': 'english literature',\n",
    "    'lit': 'literature',\n",
    "    'feminist': 'feminism',\n",
    "    'ya books': 'young adult books',\n",
    "    'ya fiction': 'young adult fiction',\n",
    "    'ya': 'young adult',\n",
    "    'non fiction': 'nonfiction',\n",
    "    'non fic': 'nonfiction',\n",
    "    'memoirs': 'memoir',\n",
    "    'distopian': 'dystopian',\n",
    "    'ya dystopian': 'young adult dystopian',\n",
    "    'ya lit': 'young adult literature'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d3e22f3-0d3f-40ce-8f4f-57634cebb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def map_genres(tag_list, genre_mapping):\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    for tag, count in tag_list:\n",
    "        tag_clean = tag.lower()\n",
    "        mapped_tag = genre_mapping.get(tag_clean, tag_clean)\n",
    "        tag_counts[mapped_tag] += count\n",
    "\n",
    "    # Convert back to list of tuples sorted by count (optional)\n",
    "    aggregated = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b1a16db-b49b-4fa2-b572-d78bc82e179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cleaning_pipeline(shelves_str, genre_mapping, blacklist_words):\n",
    "    # Step 1: Parse shelves from string\n",
    "    shelves = extract_shelves(shelves_str)\n",
    "\n",
    "    # Step 2: Map tags using genre_mapping\n",
    "    mapped = []\n",
    "    for tag, count in shelves:\n",
    "        cleaned_tag = clean_name(tag)\n",
    "        mapped_tag = genre_mapping.get(cleaned_tag, cleaned_tag)\n",
    "        mapped.append((mapped_tag, count))\n",
    "\n",
    "    # Step 3: Remove shelves if mapped tag contains ANY blacklist word\n",
    "    result = []\n",
    "    for tag, count in mapped:\n",
    "        words = tag.split()\n",
    "        if not any(bad_word in tag for bad_word in blacklist_words):\n",
    "            result.append((tag, count))\n",
    "\n",
    "    # Step 4: Aggregate repeated genres and sort\n",
    "    from collections import defaultdict\n",
    "    aggregated = defaultdict(int)\n",
    "    for tag, count in result:\n",
    "        aggregated[tag] += count\n",
    "\n",
    "    return sorted(aggregated.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eee37afc-c74a-44eb-a789-6d271f580c15",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'filtered' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample_1star[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_shelves\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_1star[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopular_shelves\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m      2\u001b[0m     apply_cleaning_pipeline, \n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39m(genre_mapping, blacklist))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1496\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard.<locals>.curried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurried\u001b[39m(x):\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m, in \u001b[0;36mapply_cleaning_pipeline\u001b[0;34m(shelves_str, genre_mapping, blacklist)\u001b[0m\n\u001b[1;32m      3\u001b[0m shelves \u001b[38;5;241m=\u001b[39m extract_shelves(shelves_str)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Map to cleaned genres\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m cleaned \u001b[38;5;241m=\u001b[39m map_genres(filtered, genre_mapping)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Step 3: Remove blacklisted terms\u001b[39;00m\n\u001b[1;32m      9\u001b[0m filtered \u001b[38;5;241m=\u001b[39m remove_blacklisted_shelves(shelves, blacklist)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'filtered' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "sample_1star['cleaned_shelves'] = sample_1star['popular_shelves'].apply(\n",
    "    apply_cleaning_pipeline, \n",
    "    args=(genre_mapping, blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e5e84-3c73-4531-957a-7192a2512dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star[['cleaned_shelves']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e579ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempting to clean the html first\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
