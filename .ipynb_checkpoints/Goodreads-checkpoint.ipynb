{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f223c3-125a-4da4-accb-d22d980ffe1f",
   "metadata": {},
   "source": [
    "# Goodreads Book Reviews Analysis - Numerical Data Exploration\n",
    "\n",
    "## Project Overview\n",
    "This project aims to analyze **Goodreads book reviews**, focusing on **1-star ratings** to understand patterns in harsh reviews. The analysis is divided into two parts:\n",
    "1. **Numerical Data Analysis** (Current Stage) - Examining numerical factors such as star ratings, review counts, and genre distributions.\n",
    "2. **Natural Language Processing (NLP) Analysis** (Next Stage) - Exploring book descriptions and text reviews to identify sentiment patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a057dee-934a-49ef-813a-0f63b2e77875",
   "metadata": {},
   "source": [
    "## Adding dataset with text reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefa3ac-fb9e-4c05-9fff-cf7cd8d38fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "chunk_size= 10000\n",
    "chunks= []\n",
    "\n",
    "with gzip.open (\"./Data/goodreads_reviews_dedup.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f): #read line by line\n",
    "        chunks.append(json.loads(line)) #convert json to stionf dict\n",
    "\n",
    "    #every chuck line, process data to write csv\n",
    "        if (i + 1) % chunk_size == 0:\n",
    "            df_chunk = pd.DataFrame(chunks)\n",
    "            df_chunk.to_csv(\"goodreads_reviews\", mode=\"a\", index= False, header = (i < chunk_size))\n",
    "            chunks = []\n",
    "        \n",
    "if chunks:\n",
    "    df_chunk = pd.DataFrame(chunks)\n",
    "    df_chunk.to_csv(\"goodreads_reviews\", mode =\"a\", index=False, header=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81556b3f-fcb7-4c51-804a-6a5d7125a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"goodreads_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea58185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7684f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['book_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "chunk_size= 10000\n",
    "chunks= []\n",
    "\n",
    "with gzip.open (\"./Data/goodreads_books.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f): #read line by line\n",
    "        chunks.append(json.loads(line)) #convert json to stionf dict\n",
    "         \n",
    "    #every chuck line, process data to write csv\n",
    "        if (i + 1) % chunk_size == 0:\n",
    "            df_chunk = pd.DataFrame(chunks)\n",
    "            df_chunk.to_csv(\"goodreads_books\", mode=\"a\", index= False, header = (i < chunk_size))\n",
    "            chunks = []\n",
    "        \n",
    "if chunks:\n",
    "    df_chunk = pd.DataFrame(chunks)\n",
    "    df_chunk.to_csv(\"goodreads_books\", mode =\"a\", index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv(\"goodreads_books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04077ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_books.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_reviews.merge(df_books, on=\"book_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d71781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ababa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_merged.drop(columns=['user_id','date_added','read_at','started_at','date_updated','read_at','kindle_asin','work_id','n_comments','asin','similar_books','series','similar_books','publication_month','publication_day','edition_information','is_ebook'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32876e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_merged.drop(columns=['format', 'num_pages', 'isbn13', 'link', 'title_without_series'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['review_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0573a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_merged['text_reviews_count']== 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['text_reviews_count'] == 0]\n",
    "#?? maybe outdated text review count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['rating'] == 0]\n",
    "#reviews that have text but no star rating was left? I am choosing to leave these out of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged= df_merged[df_merged['rating'].notna() & (df_merged['rating'] !=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this analysis I will only be focusing on english reviews\n",
    "#removing nonenglish rows and rows with no text in review_text or description. I dont think this will hurt bc the df is so large\n",
    "df_merged= df_merged.dropna(subset=['review_text','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning popular shelves column\n",
    "print(df_merged['popular_shelves'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2854c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing which shelves have the highest counts\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "#function that extracts shelf names from string lists of the shelf dictionaires\n",
    "def shelf_names(shelves_str):\n",
    "    shelves_list = ast.literal_eval(shelves_str) #convert the string to a list of dicts\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [shelf['name'] for shelf in shelves_list if 'name' in shelf] #extract 'name' value from each dict if it exists\n",
    "    return []\n",
    "\n",
    "shelf_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a68bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very large operation (takes about 100 minutes to run)\n",
    "for row in df_merged['popular_shelves'].dropna():\n",
    "    shelf_counter.update(shelf_names(row))\n",
    "\n",
    "print(shelf_counter.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc354730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "unique_shelves = list(shelf_counter.keys())\n",
    "print(f\"unique names: {len(unique_shelves)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63488b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shelf_counter.most_common(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_shelf(name):\n",
    "    return name.strip().lower().replace(\" \", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering shelf names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the author column\n",
    "print(df_merged['authors'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is already a language code column but it's not through. Try lang detect to fill in missing\n",
    "from langdetect import detect\n",
    "df_merged['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for final cleaning steps to slim down dataset futher before splitting  then saving to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9805d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split df into managable chunks for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for star in range(0,6):\n",
    "    df_star = df_merged[df_merged['rating'] == star]\n",
    "    df_star.to_csv(f\"{star}star_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "csv_files = [\"./Data/1star_reviews.csv\"]\n",
    "\n",
    "zip_path = \"./Data/1star_reviews.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file in csv_files:\n",
    "        arcname = os.path.basename(file)\n",
    "        zipf.write(file,arcname=arcname)\n",
    "\n",
    "zip_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning them to variables then checking size\n",
    "\n",
    "df_5star = pd.read_csv(\"./Data/5star_reviews.csv\")\n",
    "df_5star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6858eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4star = pd.read_csv(\"./Data/4star_reviews.csv\")\n",
    "df_4star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3star = pd.read_csv(\"./Data/3star_reviews.csv\")\n",
    "df_3star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2star = pd.read_csv(\"./Data/2star_reviews.csv\")\n",
    "df_2star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15225c65-a2b0-4325-8cc0-777fbf594670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ba3d3b-a071-4b09-8c1a-28aceec7c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m889.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da14e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 419874 entries, 0 to 419873\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Unnamed: 0          419874 non-null  int64  \n",
      " 1   book_id             419874 non-null  int64  \n",
      " 2   review_id           419874 non-null  object \n",
      " 3   rating              419874 non-null  int64  \n",
      " 4   review_text         419874 non-null  object \n",
      " 5   n_votes             419874 non-null  int64  \n",
      " 6   isbn                328665 non-null  object \n",
      " 7   text_reviews_count  419874 non-null  float64\n",
      " 8   country_code        419874 non-null  object \n",
      " 9   language_code       340979 non-null  object \n",
      " 10  popular_shelves     419874 non-null  object \n",
      " 11  average_rating      419874 non-null  float64\n",
      " 12  description         419874 non-null  object \n",
      " 13  authors             419874 non-null  object \n",
      " 14  publisher           347484 non-null  object \n",
      " 15  publication_year    358879 non-null  float64\n",
      " 16  url                 419874 non-null  object \n",
      " 17  image_url           419874 non-null  object \n",
      " 18  ratings_count       419874 non-null  float64\n",
      " 19  title               419874 non-null  object \n",
      "dtypes: float64(4), int64(4), object(12)\n",
      "memory usage: 64.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1star = pd.read_csv(\"./1star_reviews.csv\")\n",
    "df_1star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20429fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample of the smallest rating dataset to test for cleaning\n",
    "sample_1star= df_1star.sample(10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f37216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'count': '587', 'name': 'to-read'}, {'count': '76', 'name': 'romance'}, {'count': '75', 'name': 'diana-palmer'}, {'count': '26', 'name': 'contemporary-romance'}, {'count': '20', 'name': 'currently-reading'}, {'count': '17', 'name': 'harlequin'}, {'count': '14', 'name': 'western'}, {'count': '13', 'name': 'contemporary'}, {'count': '10', 'name': 'long-tall-texans'}, {'count': '10', 'name': 'books-i-own'}, {'count': '9', 'name': 'fiction'}, {'count': '9', 'name': 'cowboy'}, {'count': '8', 'name': 'palmer-diana'}, {'count': '8', 'name': 'series'}, {'count': '7', 'name': 'palmer'}, {'count': '7', 'name': 'harlequin-romance'}, {'count': '6', 'name': 'western-romance'}, {'count': '5', 'name': 'owned'}, {'count': '5', 'name': 'default'}, {'count': '5', 'name': 'my-library'}, {'count': '4', 'name': 'kindle'}, {'count': '4', 'name': 'read-in-2010'}, {'count': '3', 'name': 'audio-books'}, {'count': '3', 'name': '2010-11'}, {'count': '3', 'name': 'harlequin-wishlist'}, {'count': '3', 'name': 'books-i-have'}, {'count': '3', 'name': 'adult'}, {'count': '3', 'name': 'cowboys'}, {'count': '3', 'name': 'favorites'}, {'count': '3', 'name': 'virgin-heroine'}, {'count': '3', 'name': 'april'}, {'count': '2', 'name': 'harlequim'}, {'count': '2', 'name': 'storage1'}, {'count': '2', 'name': 'did-not-finish'}, {'count': '2', 'name': 'series-in-progress'}, {'count': '2', 'name': '150-250-pages'}, {'count': '2', 'name': 'chick-lit'}, {'count': '2', 'name': 'books'}, {'count': '2', 'name': 'on-my-shelf'}, {'count': '2', 'name': 'adult-fiction'}, {'count': '2', 'name': 'cowboy-western'}, {'count': '2', 'name': 'terjemahan'}, {'count': '2', 'name': 'genre-western'}, {'count': '2', 'name': 'undecided'}, {'count': '2', 'name': 'paper-back'}, {'count': '2', 'name': 'not-interested'}, {'count': '2', 'name': 'gramedia'}, {'count': '2', 'name': 'favourites'}, {'count': '2', 'name': 'bought'}, {'count': '2', 'name': 'romantic-suspense'}, {'count': '2', 'name': 'books-owned'}, {'count': '2', 'name': 'action'}, {'count': '2', 'name': 'library'}, {'count': '2', 'name': 'i-own'}, {'count': '2', 'name': 'small-town'}, {'count': '2', 'name': 'audiobook'}, {'count': '2', 'name': 'part-of-a-series'}, {'count': '2', 'name': 'series-romance'}, {'count': '2', 'name': 'library-books'}, {'count': '2', 'name': '2010-read'}, {'count': '2', 'name': 'harlequinromance'}, {'count': '1', 'name': '2017-read'}, {'count': '1', 'name': 'meaghan'}, {'count': '1', 'name': 'mills-and-boon'}, {'count': '1', 'name': 'my-owned-books'}, {'count': '1', 'name': 'elibrary'}, {'count': '1', 'name': '0-contemporary'}, {'count': '1', 'name': 'genre_romance'}, {'count': '1', 'name': 'seasonal-challenge'}, {'count': '1', 'name': 'best-covers'}, {'count': '1', 'name': 'read-in-2015'}, {'count': '1', 'name': 'meh'}, {'count': '1', 'name': 'all-time-favorites'}, {'count': '1', 'name': 'tbr-later'}, {'count': '1', 'name': 'harlequins'}, {'count': '1', 'name': 'books-i-own-paper'}, {'count': '1', 'name': 'angsty'}, {'count': '1', 'name': 'on-the-shelf'}, {'count': '1', 'name': '2017-challenge'}, {'count': '1', 'name': 'series-read'}, {'count': '1', 'name': 'free-borrowed'}, {'count': '1', 'name': 'paperback'}, {'count': '1', 'name': 'shelf-4-front'}, {'count': '1', 'name': '2017-bookriot-challenge'}, {'count': '1', 'name': 'vicky-to-read'}, {'count': '1', 'name': 'need-to-read-vet'}, {'count': '1', 'name': '1999-reads'}, {'count': '1', 'name': '2010-reads'}, {'count': '1', 'name': 'blom-check'}, {'count': '1', 'name': 'primary'}, {'count': '1', 'name': 'romance-modern'}, {'count': '1', 'name': 'own-to-read'}, {'count': '1', 'name': 'long-tall-texan'}, {'count': '1', 'name': 'location-nook'}, {'count': '1', 'name': 'hero-grovels'}, {'count': '1', 'name': 'brooding-hero'}, {'count': '1', 'name': 'long-tall-texans-series-bk-34'}, {'count': '1', 'name': 'harlequin-modern-romance'}, {'count': '1', 'name': 'e-books'}, {'count': '1', 'name': '3-stars'}]\n"
     ]
    }
   ],
   "source": [
    "#cleaning popular shelves column\n",
    "print(sample_1star['popular_shelves'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80c2e5fd-ac8c-4af7-9114-6c37f5b4bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing which shelves have the highest counts\n",
    "#function that extracts shelf names from string lists of the shelf dictionaires\n",
    "def shelf_names(shelves_str):\n",
    "    shelves_list = ast.literal_eval(shelves_str) #convert the string to a list of dicts\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [shelf['name'] for shelf in shelves_list if 'name' in shelf] #extract 'name' value from each dict if it exists\n",
    "    return []\n",
    "\n",
    "shelf_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c09e7d9-5d99-4472-a69b-f81dc13cd3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to-read', 29787), ('currently-reading', 27891), ('owned', 25371), ('fiction', 24933), ('favorites', 24789), ('books-i-own', 23883), ('kindle', 22146), ('ebook', 21639), ('library', 21255), ('owned-books', 20850), ('to-buy', 19779), ('ebooks', 18954), ('wish-list', 17823), ('default', 17178), ('contemporary', 16458), ('my-books', 16143), ('audiobook', 16104), ('adult', 15714), ('romance', 15672), ('audiobooks', 15231), ('i-own', 14709), ('my-library', 14559), ('did-not-finish', 14244), ('dnf', 14211), ('audio', 13941), ('abandoned', 13701), ('favourites', 13236), ('e-book', 13212), ('series', 12624), ('novels', 12618), ('read-in-2015', 12066), ('own-it', 11928), ('books', 11619), ('book-club', 11487), ('fantasy', 11481), ('e-books', 11337), ('read-in-2016', 11292), ('read-in-2014', 11220), ('adult-fiction', 11205), ('maybe', 11151), ('young-adult', 10677), ('read-in-2013', 10143), ('read-in-2017', 9447), ('mystery', 9339), ('have', 9012), ('novel', 8976), ('reviewed', 8898), ('borrowed', 8718), ('ya', 8652), ('audible', 8562), ('audio-books', 8442), ('drama', 8403), ('english', 7980), ('read-in-2012', 7929), ('didn-t-finish', 7866), ('favorite', 7659), ('tbr', 7644), ('unfinished', 7575), ('contemporary-fiction', 7485), ('audio-book', 7377)]\n"
     ]
    }
   ],
   "source": [
    "#very large operation (takes about 100 minutes to run)\n",
    "for row in sample_1star['popular_shelves'].dropna():\n",
    "    shelf_counter.update(shelf_names(row))\n",
    "\n",
    "print(shelf_counter.most_common(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1555e180-aa46-47bb-988e-f208abdee56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique names: 92620\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "unique_shelves = list(shelf_counter.keys())\n",
    "print(f\"unique names: {len(unique_shelves)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "sample_1star[['review_text','description']].sample(5, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e579ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempting to clean the html first\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
