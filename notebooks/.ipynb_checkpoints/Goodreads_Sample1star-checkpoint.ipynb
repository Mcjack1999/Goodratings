{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f223c3-125a-4da4-accb-d22d980ffe1f",
   "metadata": {},
   "source": [
    "# Goodreads Book Reviews Analysis - Sample 10,000\n",
    "\n",
    "## Purpose:\n",
    "This notebook contains the core thematic analysis pipeline applied to a 10,000-record sample of 1-star reviews from the UCSD Goodreads dataset. It was developed to enable scalable natural language processing and topic extraction before applying to the full dataset.\n",
    "\n",
    "## Focus:\n",
    "\t•\tClean and normalize review text\n",
    "\t•\tApply rule-based theme tagging with keyword dictionaries\n",
    "\t•\tUse Non-negative Matrix Factorization (NMF) to extract themes from uncategorized reviews\n",
    "\t•\tRe-assign updated themes and simplify them into primary categories (top_theme)\n",
    "\t•\tGenerate visualizations to explore patterns in dissatisfaction\n",
    "\n",
    "## Outcome:\n",
    "This notebook is the analytical heart of the project and showcases how user complaints can be interpreted, structured, and visualized using scalable NLP workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a057dee-934a-49ef-813a-0f63b2e77875",
   "metadata": {},
   "source": [
    "## Adding dataset with text reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15225c65-a2b0-4325-8cc0-777fbf594670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba3d3b-a071-4b09-8c1a-28aceec7c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e8630-0bbc-49c3-ba79-78bab435f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1star = pd.read_csv(\"../Data/1star_reviews.csv\")\n",
    "df_1star.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20429fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample of the smallest rating dataset to test for cleaning\n",
    "sample_1star= df_1star.sample(10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e579ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91281b85-de24-4850-b2be-c5e9303a627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a cleaned language column but keep NaNs\n",
    "sample_1star = sample_1star[\n",
    "    sample_1star['language_code'].isna() |\n",
    "    sample_1star['language_code'].str.lower().str.contains(r'\\ben\\b|\\beng\\b|en-', na=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc67bc-4aa3-488c-8e91-6a52c4717eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star['language_code'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62351d12-cfea-4385-b294-6fb505a54224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b8927-0ac1-4fb3-94b9-47bbb4c9f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import langdetect\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except langdetect.lang_detect_exception.LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Add 'lang' column to sample_1star\n",
    "sample_1star['lang'] = sample_1star['review_text'].apply(detect_language)\n",
    "\n",
    "# Filter for English reviews and assign to df_clean\n",
    "sample_1star = sample_1star[sample_1star['lang'] == 'en'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e35a68-d2f5-4901-838e-f8e5519f0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()                            # Lowercase\n",
    "    text = re.sub(r'<[^>]+>', '', text)            # Remove HTML tags\n",
    "    text = re.sub(r'\\s+', ' ', text)               # Normalize whitespace\n",
    "    text = re.sub(r'http\\S+', '', text)            # Remove URLs\n",
    "    text = re.sub(r'[^a-z0-9\\s.,!?\\'\"-]', '', text)  # Remove special characters except common punctuation\n",
    "    text = text.strip()                            # Trim leading/trailing whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf1634-6019-4828-9556-6c001438c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star['review_clean'] = sample_1star['review_text'].apply(clean_text)\n",
    "sample_1star['description_clean'] = sample_1star['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171ac9b-ee3b-49dd-bdb6-6e4d34cc1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star.sample(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517501b7-d944-4dd5-b728-7621b2ba211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368054ba-3c15-4d2c-a3bb-1fb784b7c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae533c9-f6e7-4432-b52b-a4de6756eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb864ddd-4cf9-48e4-be07-7570487ef3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97aa89e-d605-4acf-92f1-8dcfb4e6a33f",
   "metadata": {},
   "source": [
    "# A look into review text with and without NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc25d2-db03-4c99-80d2-1c339a4858f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Combine all review text into one big string\n",
    "all_reviews = \" \".join(review for review in sample_1star['review_clean'].dropna())\n",
    "\n",
    "# Define stopwords to exclude common words\n",
    "custom_stopwords = set(STOPWORDS)\n",
    "custom_stopwords.update([ 'book', 'read', 'one', 'really', 'even', 'get', 'know', 'make', 'thing',\n",
    "    'think', 'way', 'page', \n",
    "     'time','would', 'could', 'like', 'well', 'just', 'books',\n",
    "    'say', 'thought', 'felt', 'want', 'back', 'reading', 'see', 'go', 'going',\n",
    "    'take', 'something', 'much', 'still', 'good', 'bad', 'end', 'start',\n",
    "    'main', 'people', 'done', 'felt', 'lot', 'actually', 'put', 'will', 'first', 'use',\n",
    "    'maybe', 'find', 'say', 'said', 'try', 'trying', 'readers', 'review','books', 'reading', 'one', 'like'\n",
    "])  \n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=1000, height=600, background_color='white',\n",
    "                      stopwords=custom_stopwords, max_words=200).generate(all_reviews)\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Most Frequent Words in 1-Star Goodreads Reviews\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26c519-4dd0-4309-9c6a-57df90bd32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Use bigrams and trigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(3, 4), stop_words='english', max_features=100)\n",
    "X = vectorizer.fit_transform(sample_1star['review_clean'].dropna())\n",
    "\n",
    "# Sum the frequencies\n",
    "sum_words = X.sum(axis=0)\n",
    "phrases_freq = [(phrase, sum_words[0, idx]) for phrase, idx in vectorizer.vocabulary_.items()]\n",
    "phrases_freq = sorted(phrases_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "ngram_df = pd.DataFrame(phrases_freq, columns=['Phrase', 'Frequency'])\n",
    "\n",
    "# Display top results\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.barh(ngram_df['Phrase'][:20][::-1], ngram_df['Frequency'][:20][::-1], color='darkred')\n",
    "plt.title('Most Frequent 3-4 Word Phrases in 1-Star Reviews')\n",
    "plt.xlabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca49e0b-95c9-4bed-8564-e8603249a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Use bigrams and trigrams\n",
    "vectorizer2 = CountVectorizer(ngram_range=(4, 5), stop_words='english', max_features=100)\n",
    "X_2 = vectorizer2.fit_transform(sample_1star['review_clean'].dropna())\n",
    "\n",
    "# Sum the frequencies\n",
    "sum_words2 = X_2.sum(axis=0)\n",
    "phrases_freq2 = [(phrase, sum_words[0, idx]) for phrase, idx in vectorizer2.vocabulary_.items()]\n",
    "phrases_freq2 = sorted(phrases_freq2, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "ngram2_df = pd.DataFrame(phrases_freq2, columns=['Phrase', 'Frequency'])\n",
    "\n",
    "# Display top results\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.barh(ngram2_df['Phrase'][:20][::-1], ngram2_df['Frequency'][:20][::-1], color='darkred')\n",
    "plt.title('Most Frequent 4-5 Word Phrases in 1-Star Reviews')\n",
    "plt.xlabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987aeb2-e8d7-40a4-b2fa-61a78ad1cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram2_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4a8a5-81f5-45aa-9ed2-03dd32663039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theme mapping dictionary: theme → list of indicative phrases/keywords\n",
    "complaint_themes = {\n",
    "    'Character Issues': [\n",
    "        'main character', 'character development', 'year old', 'immature', 'annoying', 'love interest',\n",
    "        'unlikable', 'flat character', 'cardboard cutout', 'inconsistent character',\n",
    "        'poorly developed', 'shallow', 'unlikeable', 'irritating', 'stupid character',\n",
    "        'weak character', 'flawed character', 'sympathy for', 'no connection with',\n",
    "        'motivations unclear', 'acted out of character', 'forced relationship',\n",
    "        'insta-love', 'toxic relationship', 'protagonist', 'antagonist',\n",
    "        'side character', 'underdeveloped characters', 'one-dimensional',\n",
    "        'contrived motivations', 'unbelievable actions', 'lack of depth',\n",
    "        'superficial', 'self-absorbed', 'whiny', 'passive', 'aggressive',\n",
    "        'jerk', 'bitch', 'mary sue', 'gary stu', 'author insert',\n",
    "        'wish fulfillment character', 'unearned development',\n",
    "        'rushed character arc', 'stagnant character', 'rely on stereotypes'\n",
    "    ],\n",
    "    'Plot/Structure': [\n",
    "        'storyline', 'plot', 'spoiler alert', 'twist', 'didn make sense', 'nothing happened',\n",
    "        'predictable', 'rushed ending', 'slow burn', 'pacing issues', 'convoluted plot',\n",
    "        'plot holes', 'deus ex machina', 'uneven pacing', 'anticlimactic', 'pointless subplot',\n",
    "        'disjointed', 'rambling', 'contrived', 'repetitive plot points', 'no resolution',\n",
    "        'weak plot', 'thin plot', 'overly complicated', 'underdeveloped plot',\n",
    "        'too much exposition', 'info dump', 'lack of focus', 'meandering',\n",
    "        'circular narrative', 'incoherent', 'illogical', 'unrealistic plot',\n",
    "        'convenient coincidences', 'forced conflict', 'lack of stakes',\n",
    "        'unnecessary scenes', 'padding', 'false climax', 'unsatisfying ending',\n",
    "        'cliffhanger with no payoff', 'sequel baiting', 'felt incomplete'\n",
    "    ],\n",
    "    'Writing Style': [\n",
    "        'writing style', 'bad writing', 'purple prose', 'repetitive', 'boring', 'poorly written',\n",
    "        'clunky prose', 'awkward phrasing', 'stilted dialogue', 'unnatural dialogue',\n",
    "        'telling not showing', 'over descriptive', 'underdeveloped', 'simplistic writing',\n",
    "        'pretentious writing', 'amateurish', 'grammatical errors', 'typos', 'editing issues',\n",
    "        'poor sentence structure', 'weak vocabulary', 'monotonous', 'flow issues',\n",
    "        'choppy', 'dense writing', 'impenetrable', 'overuse of adjectives',\n",
    "        'clichés', 'hackneyed', 'trite', 'melodramatic', 'overwrought',\n",
    "        'infodumping through dialogue', 'dialogue felt forced',\n",
    "        'internal monologue overuse', 'head hopping', 'inconsistent tense'\n",
    "    ],\n",
    "    'Engagement': [\n",
    "        'couldn finish', 'waste time', 'feel like', 'just didn', 'didn like', 'slow', 'dragged',\n",
    "        'lost interest', 'tedious', 'struggled to get through', 'hard to follow',\n",
    "        'unengaging', 'dull', 'plodding', 'sleep-inducing', 'wish i hadn read',\n",
    "        'skimming', 'couldn\\'t connect', 'no emotional impact', 'didn care about',\n",
    "        'wanted it to end', 'a chore to read', 'painful to read', 'eyes glazed over',\n",
    "        'mind wandered', 'checked page count constantly', 'felt like a slog',\n",
    "        'momentum stalled', 'pacing was off', 'never invested', 'no suspense',\n",
    "        'lacked excitement', 'failed to captivate'\n",
    "    ],\n",
    "    'Expectations vs Reality': [\n",
    "        'like book', 'expected', 'thought would', 'overhyped',\n",
    "        'not what i expected', 'misleading description', 'different from summary',\n",
    "        'disappointed', 'underwhelming', 'fell flat', 'not as good as', 'wasted potential',\n",
    "        'false advertising', 'bait and switch', 'promised more than delivered',\n",
    "        'didn live up to the hype', 'genre wasn\\'t what i thought',\n",
    "        'cover was misleading', 'title was misleading', 'blurb was inaccurate',\n",
    "        'reviews were misleading', 'fanbase is delusional'\n",
    "    ],\n",
    "    'Offensive Content': [\n",
    "        'offensive', 'problematic', 'sexist', 'racist', 'abuse', 'trigger',\n",
    "        'misogynistic', 'homophobic', 'ableist', 'culturally insensitive',\n",
    "        'gory', 'disturbing', 'gratuitous violence', 'sexual assault',\n",
    "        'animal cruelty', 'hate speech', 'stereotypes', 'colorism', 'fatphobia',\n",
    "        'victim blaming', 'glorification of violence', 'romanticizing abuse',\n",
    "        'toxic masculinity', 'white savior trope', 'bury your gays trope',\n",
    "        'fridging', 'rape as plot device', 'unnecessary graphic detail'\n",
    "    ],\n",
    "    'Genre Mismatch': [\n",
    "        'not romance', 'not fantasy', 'genre', 'more thriller than',\n",
    "        'felt like', 'marketed as', 'supposed to be', 'wrong genre',\n",
    "        'elements of', 'blended genres poorly', 'not enough',\n",
    "        'too much [genre element]', 'this isn\\'t [genre]', 'where\\'s the',\n",
    "        'misleading genre tag', 'didn fit the category', 'cross-genre failure',\n",
    "        'felt like a different genre entirely', 'no present'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672822f-7c4c-49ec-9c85-2617a61884e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_themes(review_text, theme_map):\n",
    "    review_text = review_text.lower()\n",
    "    matched_themes = []\n",
    "\n",
    "    for theme, keywords in theme_map.items():\n",
    "        if any(kw in review_text for kw in keywords):\n",
    "            matched_themes.append(theme)\n",
    "\n",
    "    return matched_themes if matched_themes else ['Uncategorized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879a256-fb87-49cd-8ff1-ae8751ee4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the theme assignment to your cleaned reviews\n",
    "sample_1star['complaint_themes'] = sample_1star['review_clean'].apply(\n",
    "    lambda x: assign_themes(x, complaint_themes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40135f2f-9991-4ad9-aa08-95cadb2bdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# Flatten list of themes and count\n",
    "theme_counts = Counter(chain.from_iterable(sample_1star['complaint_themes']))\n",
    "print(theme_counts.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ae240-8a7c-4b2e-82aa-69e6ea73f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Assuming your DataFrame is named 'sample_1star'\n",
    "uncategorized_df = sample_1star[sample_1star['complaint_themes'].apply(lambda x: 'Uncategorized' in x)].copy()\n",
    "uncategorized_reviews = uncategorized_df['review_clean'].dropna().tolist()\n",
    "\n",
    "# 1. Define Stopwords (using your combined list)\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "wordcloud_stopwords = set(STOPWORDS)\n",
    "custom_stopwords = set([\n",
    "    'book', 'read', 'one', 'really', 'even', 'get', 'know', 'make', 'thing',\n",
    "    'think', 'way', 'page', 'time', 'would', 'could', 'like', 'well', 'just', 'books',\n",
    "    'say', 'thought', 'felt', 'want', 'back', 'reading', 'see', 'go', 'going',\n",
    "    'take', 'something', 'much', 'still', 'good', 'bad', 'end', 'start',\n",
    "    'main', 'people', 'done', 'felt', 'lot', 'actually', 'put', 'will', 'first', 'use',\n",
    "    'maybe', 'find', 'say', 'said', 'try', 'trying', 'readers', 'review'\n",
    "])\n",
    "combined_stopwords_set = nltk_stopwords.union(wordcloud_stopwords).union(custom_stopwords)\n",
    "\n",
    "# 2. Lemmatization and Stopword Removal for Uncategorized Reviews\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "processed_uncategorized_reviews = []\n",
    "for review in uncategorized_reviews:\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    processed_tokens = [token for token in lemmatized_tokens if token not in combined_stopwords_set]\n",
    "    processed_uncategorized_reviews.append(\" \".join(processed_tokens))\n",
    "\n",
    "# 3. Feature Extraction with TF-IDF for Uncategorized Reviews\n",
    "tfidf_vectorizer_uncat = TfidfVectorizer(stop_words=list(combined_stopwords_set),\n",
    "                                        ngram_range=(1, 3),\n",
    "                                        max_df=0.90,\n",
    "                                        min_df=2)\n",
    "tfidf_matrix_uncat = tfidf_vectorizer_uncat.fit_transform(processed_uncategorized_reviews)\n",
    "feature_names_uncat = tfidf_vectorizer_uncat.get_feature_names_out()\n",
    "\n",
    "# 4. Train the NMF Model for Uncategorized Reviews\n",
    "num_topics_uncat = 7  # You can experiment with the number of topics for the uncategorized data\n",
    "nmf_model_uncat = NMF(n_components=num_topics_uncat, random_state=42, max_iter=300)\n",
    "nmf_model_uncat.fit(tfidf_matrix_uncat)\n",
    "\n",
    "# 5. Analyze the Topics for Uncategorized Reviews\n",
    "print(\"\\nNMF Topics for Uncategorized Reviews:\")\n",
    "for topic_idx, topic in enumerate(nmf_model_uncat.components_):\n",
    "    top_words_indices = topic.argsort()[:-21:-1]\n",
    "    top_words = [feature_names_uncat[i] for i in top_words_indices]\n",
    "    print(f\"Uncategorized Topic {topic_idx + 1}: {' '.join(top_words)}\")\n",
    "\n",
    "# 6. Get Topic Assignments for Uncategorized Reviews (Optional)\n",
    "doc_topic_matrix_uncat = nmf_model_uncat.transform(tfidf_matrix_uncat)\n",
    "dominant_topics_uncat = [row.argmax() + 1 for row in doc_topic_matrix_uncat]\n",
    "\n",
    "# 7. Add NMF Topic Assignments to the Uncategorized DataFrame (Optional)\n",
    "uncategorized_df['nmf_topic_uncat'] = pd.Series(dominant_topics_uncat, index=uncategorized_df.index[:len(dominant_topics_uncat)])\n",
    "\n",
    "# Merge the NMF topic assignments back into the original DataFrame\n",
    "sample_1star = pd.merge(sample_1star, uncategorized_df[['review_id', 'nmf_topic_uncat']], on='review_id', how='left')\n",
    "\n",
    "print(\"\\nDataFrame with NMF Topic Labels for Uncategorized (First 10):\")\n",
    "print(sample_1star[['review_clean', 'complaint_themes', 'nmf_topic_uncat']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfbf5a-3fef-4cc0-8c9d-4ca982ee34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_themes_updated = {\n",
    "    'Character Issues': [\n",
    "        'main character', 'character development', 'year old', 'immature', 'annoying', 'love interest',\n",
    "        'unlikable', 'flat character', 'cardboard cutout', 'inconsistent character',\n",
    "        'poorly developed', 'shallow', 'unlikeable', 'irritating', 'stupid character',\n",
    "        'weak character', 'flawed character', 'sympathy for', 'no connection with',\n",
    "        'motivations unclear', 'acted out of character', 'forced relationship',\n",
    "        'insta-love', 'toxic relationship', 'protagonist', 'antagonist',\n",
    "        'side character', 'underdeveloped characters', 'one-dimensional',\n",
    "        'contrived motivations', 'unbelievable actions', 'lack of depth',\n",
    "        'superficial', 'self-absorbed', 'whiny', 'passive', 'aggressive',\n",
    "        'jerk', 'bitch', 'mary sue', 'gary stu', 'author insert',\n",
    "        'wish fulfillment character', 'unearned development',\n",
    "        'rushed character arc', 'stagnant character', 'rely on stereotypes',\n",
    "        'stupid', 'hate'  # Added from Strong Negative Sentiment\n",
    "    ],\n",
    "    'Plot/Structure': [\n",
    "        'storyline', 'plot', 'spoiler alert', 'twist', 'didn make sense', 'nothing happened',\n",
    "        'predictable', 'rushed ending', 'slow burn', 'pacing issues', 'convoluted plot',\n",
    "        'plot holes', 'deus ex machina', 'uneven pacing', 'anticlimactic', 'pointless subplot',\n",
    "        'disjointed', 'rambling', 'contrived', 'repetitive plot points', 'no resolution',\n",
    "        'weak plot', 'thin plot', 'overly complicated', 'underdeveloped plot',\n",
    "        'too much exposition', 'info dump', 'lack of focus', 'meandering',\n",
    "        'circular narrative', 'incoherent', 'illogical', 'unrealistic plot',\n",
    "        'convenient coincidences', 'forced conflict', 'lack of stakes',\n",
    "        'unnecessary scenes', 'padding', 'false climax', 'unsatisfying ending',\n",
    "        'cliffhanger with no payoff', 'sequel baiting', 'felt incomplete',\n",
    "        'story' # Added from Uncategorized Topic 1 and 4\n",
    "    ],\n",
    "    'Writing Style': [\n",
    "        'writing style', 'bad writing', 'purple prose', 'repetitive', 'boring', 'poorly written',\n",
    "        'clunky prose', 'awkward phrasing', 'stilted dialogue', 'unnatural dialogue',\n",
    "        'telling not showing', 'over descriptive', 'underdeveloped', 'simplistic writing',\n",
    "        'pretentious writing', 'amateurish', 'grammatical errors', 'typos', 'editing issues',\n",
    "        'poor sentence structure', 'weak vocabulary', 'monotonous', 'flow issues',\n",
    "        'choppy', 'dense writing', 'impenetrable', 'overuse of adjectives',\n",
    "        'clichés', 'hackneyed', 'trite', 'melodramatic', 'overwrought',\n",
    "        'infodumping through dialogue', 'dialogue felt forced',\n",
    "        'internal monologue overuse', 'head hopping', 'inconsistent tense',\n",
    "        'written' # Added from Uncategorized Topic 4\n",
    "    ],\n",
    "    'Engagement': [\n",
    "        'couldn finish', 'waste time', 'feel like', 'just didn', 'didn like', 'slow', 'dragged',\n",
    "        'lost interest', 'tedious', 'struggled to get through', 'hard to follow',\n",
    "        'unengaging', 'dull', 'plodding', 'sleep-inducing', 'wish i hadn read',\n",
    "        'skimming', 'couldn\\'t connect', 'no emotional impact', 'didn care about',\n",
    "        'wanted it to end', 'a chore to read', 'painful to read', 'eyes glazed over',\n",
    "        'mind wandered', 'checked page count constantly', 'felt like a slog',\n",
    "        'momentum stalled', 'pacing was off', 'never invested', 'no suspense',\n",
    "        'lacked excitement', 'failed to captivate',\n",
    "        'couldn\\'t continue', 'gave up', 'stopped reading', 'dnf', 'did not finish',\n",
    "        'bored', 'finish', 'disappointment', 'wa' # Added from NMF Topics\n",
    "    ],\n",
    "    'Expectations vs Reality': [\n",
    "        'like book', 'expected', 'thought would', 'overhyped',\n",
    "        'not what i expected', 'misleading description', 'different from summary',\n",
    "        'disappointed', 'underwhelming', 'fell flat', 'not as good as', 'wasted potential',\n",
    "        'false advertising', 'bait and switch', 'promised more than delivered',\n",
    "        'didn live up to the hype', 'genre wasn\\'t what i thought',\n",
    "        'cover was misleading', 'title was misleading', 'blurb was inaccurate',\n",
    "        'reviews were misleading', 'fanbase is delusional',\n",
    "        'waste of time', 'waste of money', 'didn\\'t feel worth it', 'awful', 'terrible' # Added from NMF Topics\n",
    "    ],\n",
    "    'Offensive Content': [\n",
    "        'offensive', 'problematic', 'sexist', 'racist', 'abuse', 'trigger',\n",
    "        'misogynistic', 'homophobic', 'ableist', 'culturally insensitive',\n",
    "        'gory', 'disturbing', 'gratuitous violence', 'sexual assault',\n",
    "        'animal cruelty', 'hate speech', 'stereotypes', 'colorism', 'fatphobia',\n",
    "        'victim blaming', 'glorification of violence', 'romanticizing abuse',\n",
    "        'toxic masculinity', 'white savior trope', 'bury your gays trope',\n",
    "        'fridging', 'rape as plot device', 'unnecessary graphic detail'\n",
    "    ],\n",
    "    'Genre Mismatch': [\n",
    "        'not romance', 'not fantasy', 'genre', 'more thriller than',\n",
    "        'felt like', 'marketed as', 'supposed to be', 'wrong genre',\n",
    "        'elements of', 'blended genres poorly', 'not enough',\n",
    "        'too much [genre element]', 'this isn\\'t [genre]', 'where\\'s the',\n",
    "        'misleading genre tag', 'didn fit the category', 'cross-genre failure',\n",
    "        'felt like a different genre entirely', 'no present'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3856f6-df6e-495c-9af5-06ddc6604f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_themes_updated(review_text, theme_map):\n",
    "    review_text = review_text.lower()\n",
    "    matched_themes = []\n",
    "\n",
    "    for theme, keywords in theme_map.items():\n",
    "        if any(kw in review_text for kw in keywords):\n",
    "            matched_themes.append(theme)\n",
    "\n",
    "    return matched_themes if matched_themes else ['Uncategorized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce4558-0c72-4c91-b7ce-38111d7cb0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the updated theme assignment and store in the correct column\n",
    "sample_1star['complaint_themes_updated'] = sample_1star['review_clean'].apply(\n",
    "    lambda x: assign_themes_updated(x, complaint_themes_updated)\n",
    ")\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# Flatten list of themes and count the updated themes\n",
    "theme_counts_updated = Counter(chain.from_iterable(sample_1star['complaint_themes_updated']))\n",
    "print(theme_counts_updated.most_common())\n",
    "\n",
    "print(\"\\nDataFrame with Updated Complaint Themes (First 10):\")\n",
    "print(sample_1star[['review_clean', 'complaint_themes', 'complaint_themes_updated']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea54eeb-8df1-45e3-a30b-11be327d6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_palette = { #distinct under colorblind simulations\n",
    "    'Engagement': '#1b9e77',          # dark teal\n",
    "    'Plot/Structure': '#d95f02',      # orange\n",
    "    'Character Issues': '#7570b3',    # purple-blue\n",
    "    'Writing Style': '#e7298a',       # reddish pink\n",
    "    'Expectations vs Reality': '#66a61e',  # olive green\n",
    "    'Genre Mismatch': '#e6ab02',      # yellow-brown\n",
    "    'Offensive Content': '#a6761d',   # brown \n",
    "    'Uncategorized': '#666666'        # dark gray (if every shown)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c38c3-e8c9-4309-a0c2-503eb373c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 'Uncategorized' and sort by frequency\n",
    "filtered_theme_counts = {k: v for k, v in theme_counts_updated.items() if k.lower() != 'uncategorized'}\n",
    "top_themes = sorted(filtered_theme_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "labels, counts = zip(*top_themes)\n",
    "\n",
    "# Apply your fixed, colorblind-accessible palette\n",
    "colors = [theme_palette[label] for label in labels]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(labels, counts, color=colors)\n",
    "\n",
    "# Title and axis\n",
    "plt.title(\"What Are the Most Common Complaint Themes in 1-Star Reviews?\", fontsize=16, weight='bold')\n",
    "plt.xlabel(\"Number of Reviews\", fontsize=12)\n",
    "\n",
    "# Add value + percentage labels\n",
    "total = sum(counts)\n",
    "for bar, count in zip(bars, counts):\n",
    "    percent = (count / total) * 100\n",
    "    plt.text(\n",
    "        bar.get_width() + 5,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{count} ({percent:.1f}%)\",\n",
    "        va='center', fontsize=10\n",
    "    )\n",
    "\n",
    "# Visual refinements\n",
    "plt.gca().invert_yaxis()  # Highest count on top\n",
    "plt.grid(False)\n",
    "plt.figtext(0.5, -0.05,\n",
    "            \"Themes extracted from rule-based keyword matching in review text.\",\n",
    "            wrap=True, horizontalalignment='center', fontsize=10)\n",
    "plt.xlim(0, max(counts) * 1.15)  # Adds 15% padding to the right\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save then show\n",
    "plt.savefig('themes_1star_reviews.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a7b567-9b53-43f5-a71a-bd4e306e75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80ed7c-c4f2-44b8-88bb-0e59535d474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Base scatterplot\n",
    "sns.scatterplot(\n",
    "    data=sample_1star,\n",
    "    x='average_rating',\n",
    "    y='ratings_count',\n",
    "    alpha=0.3,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "# Top books — no duplicate titles\n",
    "top_books = (\n",
    "    sample_1star.sort_values(by='ratings_count', ascending=False)\n",
    "    .drop_duplicates(subset='title')\n",
    "    .head(3)\n",
    ")\n",
    "\n",
    "# Highlight top books with custom markers and legend\n",
    "for _, row in top_books.iterrows():\n",
    "    plt.scatter(row['average_rating'], row['ratings_count'], s=100, marker='X', label=row['title'], zorder=5)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Do Low-Rated Books Still Get High Average Ratings?\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Average Goodreads Rating\", fontsize=12)\n",
    "plt.ylabel(\"Total Ratings Count (log scale)\", fontsize=12)\n",
    "\n",
    "# Legend\n",
    "plt.legend(title='Top Rated Books with the Most 1-Star Reviewers', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"low_rated_books_high_rating_legend.jpg\", format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf16f1-5422-4ef3-9b5e-497bec5c554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the first complaint theme (or 'Uncategorized')\n",
    "\n",
    "sample_1star['top_theme'] = sample_1star['complaint_themes_updated'].apply(lambda x: x[0] if isinstance(x, list) and x else 'Uncategorized'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0a210-ddf6-44b0-a031-ce8fb838c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate titles to avoid overplotting books reviewed multiple times\n",
    "unique_books = sample_1star.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973b764-3246-43ee-8f41-18532f172cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Drop duplicate book titles to avoid overplotting\n",
    "unique_books = sample_1star.drop_duplicates(subset='title')\n",
    "\n",
    "# Get top-rated book (by ratings count) per complaint theme\n",
    "top_books_by_theme = (\n",
    "    unique_books\n",
    "    .sort_values(by='ratings_count', ascending=False)\n",
    "    .groupby('top_theme')\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Plot setup\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Base scatterplot\n",
    "sns.scatterplot(\n",
    "    data=unique_books,\n",
    "    x='average_rating',\n",
    "    y='ratings_count',\n",
    "    hue='top_theme',\n",
    "    palette=theme_palette,\n",
    "    alpha=0.4,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Highlight top books per theme with larger X markers\n",
    "legend_handles = []\n",
    "for _, row in top_books_by_theme.iterrows():\n",
    "    plt.scatter(\n",
    "        row['average_rating'],\n",
    "        row['ratings_count'],\n",
    "        s=120,\n",
    "        marker='X',\n",
    "        color=theme_palette.get(row['top_theme'], '#000000'),\n",
    "        edgecolor='black',\n",
    "        linewidth=1.0,\n",
    "        zorder=5\n",
    "    )\n",
    "    legend_handles.append(mpatches.Patch(\n",
    "        color=theme_palette.get(row['top_theme'], '#000000'),\n",
    "        label=f\"{row['top_theme']}: {row['title']}\"\n",
    "    ))\n",
    "\n",
    "# Axis settings\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Average Goodreads Rating\", fontsize=12)\n",
    "plt.ylabel(\"Total Ratings Count (log scale)\", fontsize=12)\n",
    "plt.title(\"Do Low-Rated Books Still Get High Average Ratings (w/Complaint Themes)?\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Combined legend: themes and top books\n",
    "plt.legend(handles=legend_handles, title=\"Top Book per Theme\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('low_rated_books_by_theme_highlights.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df01fa6-ab29-49cb-8b0e-809077b7609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by median to show themes in order\n",
    "theme_order = (\n",
    "    sample_1star.groupby('top_theme')['average_rating']\n",
    "    .median()\n",
    "    .sort_values()\n",
    "    .index\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(\n",
    "    x='top_theme',\n",
    "    y='average_rating',\n",
    "    data=sample_1star,\n",
    "    order=theme_order,\n",
    "    palette=theme_palette\n",
    ")\n",
    "\n",
    "# Add median labels above each box\n",
    "medians = sample_1star.groupby('top_theme')['average_rating'].median().reindex(theme_order)\n",
    "for i, (theme, median) in enumerate(medians.items()):\n",
    "    plt.text(i, median + 0.03, f\"{median:.2f}\", ha='center', fontsize=10, weight='bold')\n",
    "\n",
    "# Labels and styling\n",
    "plt.title(\"Distribution of Average Goodreads Rating by Top Complaint Theme\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Top Complaint Theme\", fontsize=12)\n",
    "plt.ylabel(\"Average Goodreads Rating\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "sns.despine()\n",
    "\n",
    "# Footnote for interpretation\n",
    "plt.figtext(0.5, -0.08,\n",
    "            \"Box represents IQR; whiskers extend to 1.5×IQR. Points outside are outliers. Median shown above each box.\",\n",
    "            wrap=True, horizontalalignment='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.savefig('avg_goodreads_rating_by_theme_boxplot.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c0316-668d-401b-9cf2-37c03f09852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "sns.boxplot(x='top_theme', y='ratings_count', data=sample_1star, palette=theme_palette)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title(\"Distribution of Total Ratings Count (Log Scale) by Top Complaint Theme\", fontsize=18, fontweight='bold')\n",
    "plt.xlabel(\"Top Complaint Theme\", fontsize=14)\n",
    "plt.ylabel(\"Total Ratings Count (Log Scale)\", fontsize=14)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "sns.despine()\n",
    "\n",
    "plt.figtext(0.5, -0.15,\n",
    "            \"Note: This box plot shows the distribution of the total number of ratings (on a logarithmic scale) for books that received 1-star reviews categorized under each theme. The log scale is used to handle the skewed distribution of ratings counts. The box represents the IQR, the line inside is the median, and the whiskers extend to 1.5 times the IQR. Points outside the whiskers are outliers.\",\n",
    "            wrap=True, horizontalalignment='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.savefig('distribution_total_ratings_logscale_by_complaint_theme.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99df98-f1d7-4ca1-b644-5e47bc9977f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filtered year counts\n",
    "sample_1star_clean = sample_1star[(sample_1star['publication_year'] >= 1990) & \n",
    "                                  (sample_1star['publication_year'] <= 2018)]\n",
    "\n",
    "# Generate a complete index from 1990–2020 (so every year is shown)\n",
    "year_range = list(range(1990, 2018))\n",
    "\n",
    "# Count and reindex to include all years\n",
    "year_counts = sample_1star_clean['publication_year'].value_counts().sort_index()\n",
    "year_counts = year_counts.reindex(year_range, fill_value=0)\n",
    "\n",
    "# --- STEP 2: Plot the Data ---\n",
    "highlight_years = [2011, 2012, 2013]\n",
    "colors = ['orange' if year in highlight_years else 'gray' for year in year_counts.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars = ax.bar(year_counts.index, year_counts.values, color=colors)\n",
    "\n",
    "# Add exact labels for 2011–2013 just above bars (except 2013, which we'll bold separately)\n",
    "for bar in bars:\n",
    "    year = int(bar.get_x() + bar.get_width() / 2)\n",
    "    height = bar.get_height()\n",
    "    if year in highlight_years and year != 2013:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height + 5,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "# Axis settings\n",
    "ax.set_title(\"When Were the Most 1-Star Rated Books Published?\", fontsize=16)\n",
    "ax.set_xlabel(\"Publication Year\")\n",
    "ax.set_ylabel(\"Number of 1-Star Reviews\")\n",
    "ax.set_xticks(year_range)\n",
    "# Bold the label for 2013\n",
    "xtick_labels = []\n",
    "for year in year_range:\n",
    "    if year == 2013:\n",
    "        xtick_labels.append(f'$\\\\bf{{{year}}}$')  # LaTeX bold\n",
    "    else:\n",
    "        xtick_labels.append(str(year))\n",
    "\n",
    "ax.set_xticklabels(xtick_labels, rotation=45, fontsize=9)\n",
    "# Remove vertical gridlines\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "ax.grid(axis='x', visible=False)\n",
    "\n",
    "# Highlight 2013 value in bold above the bar\n",
    "highlight_year = 2013\n",
    "highlight_value = year_counts[highlight_year]\n",
    "\n",
    "ax.annotate(f'{highlight_value}',\n",
    "            xy=(highlight_year, highlight_value),\n",
    "            xytext=(0, 5),\n",
    "            textcoords='offset points',\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=10,\n",
    "            fontweight='bold')  # Make the label bold\n",
    "\n",
    "# Add padding above the tallest bar\n",
    "ax.set_ylim(0, year_counts.max() + 80)\n",
    "\n",
    "# Add a footnote\n",
    "plt.figtext(0.5, -0.05,\n",
    "            \"Note: Spike between 2011–2013 may reflect changes in Goodreads review activity or publishing trends.\",\n",
    "            wrap=True, horizontalalignment='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('when_were_most_1star_reviews_published.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff6ec8-aefc-4dd8-879b-5a13f7c979cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_counts_by_year = theme_counts_by_year[theme_palette.keys()]\n",
    "\n",
    "# Plot\n",
    "ax = theme_counts_by_year.plot(\n",
    "    kind='bar',\n",
    "    figsize=(14, 8),\n",
    "    color=[theme_palette[col] for col in theme_counts_by_year.columns]\n",
    ")\n",
    "\n",
    "# Formatting\n",
    "ax.set_title(\"Number of 1-Star Reviews by Top Complaint Theme (2011–2014)\", fontsize=18, fontweight='bold')\n",
    "ax.set_xlabel(\"Publication Year\", fontsize=14)\n",
    "ax.set_ylabel(\"Number of 1-Star Reviews\", fontsize=14)\n",
    "ax.tick_params(axis='x', labelrotation=0, labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "ax.legend(title='Top Complaint Theme', fontsize=12)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('1star_reviews_by_theme_2011_2014.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd462de6-2d66-47c9-842f-d6558543e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year bins\n",
    "bins = list(range(1990, 2021, 5))\n",
    "labels = [f'{i}-{i+4}' for i in bins[:-1]]\n",
    "sample_1star['year_bin'] = pd.cut(sample_1star['publication_year'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Group by year bin and top_theme\n",
    "theme_by_year = sample_1star.groupby('year_bin')['top_theme'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 9))\n",
    "ax = theme_by_year.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    color=[theme_palette.get(col, '#cccccc') for col in theme_by_year.columns],  # apply theme_palette\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "plt.title(\"Proportion of Top Complaint Themes by Publication Year (5-Year Bins)\", fontsize=18, fontweight='bold')\n",
    "plt.xlabel(\"Publication Year Bin\", fontsize=14)\n",
    "plt.ylabel(\"Proportion of Reviews\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.legend(title='Top Complaint Theme', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "# Add percentage labels\n",
    "for i, bin_label in enumerate(theme_by_year.index):\n",
    "    y_offset = 0\n",
    "    for theme in theme_by_year.columns:\n",
    "        height = theme_by_year.loc[bin_label, theme]\n",
    "        if height > 0.1:\n",
    "            plt.text(\n",
    "                i,\n",
    "                y_offset + height / 2,\n",
    "                f'{(height * 100):.0f}%',\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                fontsize=9,\n",
    "                color='white' if height > 0.2 else 'black'\n",
    "            )\n",
    "        y_offset += height\n",
    "\n",
    "# Add caption\n",
    "plt.figtext(\n",
    "    0.5, -0.05,\n",
    "    \"Note: This stacked bar chart shows the proportion of each top complaint theme within 5-year publication year bins. \"\n",
    "    \"The height of each colored segment represents the proportion of reviews belonging to that theme within that time period.\",\n",
    "    wrap=True, horizontalalignment='center', fontsize=10\n",
    ")\n",
    "\n",
    "# Save and show\n",
    "plt.savefig('proportion_complaint_themes_by_year_bin.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Optional: Clean up temporary column\n",
    "sample_1star.drop(columns=['year_bin'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589d03e-fb33-4208-9880-1d87a63b2cd3",
   "metadata": {},
   "source": [
    "# A look into shelves - the conundrum of genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9971a-53ed-41e6-8d8b-c5ee1dfc8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85d8bb-c90d-4f6a-b106-8ce3f07f0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning popular shelves column\n",
    "print(sample_1star['popular_shelves'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd5ead-1e29-4827-a9c8-128f53a1c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing which shelves have the highest counts\n",
    "#function that extracts shelf names from string lists of the shelf dictionaires\n",
    "def shelf_names(shelves_str):\n",
    "    shelves_list = ast.literal_eval(shelves_str) #convert the string to a list of dicts\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [shelf['name'] for shelf in shelves_list if 'name' in shelf] #extract 'name' value from each dict if it exists\n",
    "    return []\n",
    "\n",
    "shelf_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf90008-d9e7-4b48-9cf2-a2a4e786e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very large operation (takes about 100 minutes to run)\n",
    "for row in sample_1star['popular_shelves'].dropna():\n",
    "    shelf_counter.update(shelf_names(row))\n",
    "\n",
    "print(shelf_counter.most_common(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8300c11-b6b5-436e-bc20-adfb2c092756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "unique_shelves = list(shelf_counter.keys())\n",
    "print(f\"unique names: {len(unique_shelves)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed261f74-aa00-4f32-8426-0b1274f26865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "blacklist = [\n",
    "    # 1. Reading status\n",
    "    'to-read', 'read-in-2016', 'currently-reading', 'tbr', 'read-2016', 'read-2015', 'read-2014',\n",
    "    'read-2013', 'read-2012', 'read-2011', 'read-2010', 're-read', 'reread', 'to-reread', 'already-read',\n",
    "    'read-again', 'read-aloud', 'read-alouds', 'read-fiction', 'read-in-school', 'read-as-a-kid',\n",
    "    'read-comics', 'read-next', 'read-2009', 'read-in-english',\n",
    "\n",
    "    # 2. Ownership/location\n",
    "    'owned', 'my-books', 'library', 'kindle', 'ebooks', 'books-i-own', 'to-buy', 'owned-books',\n",
    "    'i-own', 'my-library', 'own-it', 'borrowed', 'on-my-shelf', 'books-i-have', 'bookshelf',\n",
    "    'home-library', 'my-bookshelf', 'own-to-read', 'own-ebook', 'my-ebooks', 'owned-tbr',\n",
    "    'ebooks-i-own', 'own-kindle', 'owned-not-read', 'owned-but-not-read', 'own-on-kindle',\n",
    "    'kindle-owned', 'own-unread', 'owned-unread', 'owned-ebook', 'own-a-copy', 'my-kindle-books',\n",
    "    'owned-kindle', 'own-tbr', 'kindle-library', 'books-owned', 'kindle-to-read', 'not-owned',\n",
    "    'do-not-own', 'owned-not-read', 'owned-but-not-read', 'own-unread', 'own-a-copy',\n",
    "\n",
    "    # 3. Format or device\n",
    "    'audiobook', 'ebook', 'paperback', 'hardcover', 'audiobooks', 'audio', 'e-book', 'e-books',\n",
    "    'audio-books', 'audio-book', 'audible', 'library-book', 'kindle-books', 'nook', 'on-kindle',\n",
    "    'netgalley', 'overdrive', 'pdf', 'epub', 'ibooks', 'kobo', 'kindle-unlimited', 'digital',\n",
    "    'graphic', 'ebook-owned', 'epub', 'e-reader', 'calibre', 'ibooks', 'kobo', 'downloaded',\n",
    "    'kindle-book', 'ebooks-i-own',\n",
    "\n",
    "    # 4. Rating/review-based\n",
    "    '5-stars', 'favorites', 'favourites', 'favorite', 'favorite-books', 'favorite-series',\n",
    "    'my-favorites', 'favorite-authors', 'favorite-author', 'faves', 'favourite', 'fav',\n",
    "    'gave-up-on', 'gave-up', 'did-not-finish', 'dnf', 'abandoned', 'unfinished', 'didn-t-finish',\n",
    "    'couldn-t-finish', 'could-not-finish', 'not-finished', 'not-read', 'never-finished', 'paused',\n",
    "    'stopped-reading', 'not-for-me', 'nope', 'meh', 'dnf', 'review', 'reviewed',\n",
    "\n",
    "    # 5. Challenge or year-based\n",
    "    '2016-reading-challenge', '2017-reading-challenge', '2015-reading-challenge', '2014-read',\n",
    "    '2015-reads', '2014-reads', '2013-reads', '2012-reads', '2011-reads', '2010-reads', '2016-reads',\n",
    "    '2015-books', '2014-books', '2013-books', '2012-books', '2017-reads', '2017-books',\n",
    "    '2017-read', '2017-release', '2017-reading-list', '2017-books-read', 'books-read-in-2016',\n",
    "    'books-read-in-2015', 'books-read-in-2014', 'books-read-in-2013', 'books-read-in-2012',\n",
    "    'books-read-in-2017', 'books-read-in-2011', 'books-read-in-2010', 'read-in-2015',\n",
    "    'read-in-2014', 'read-in-2013', 'read-in-2012', 'read-in-2011', 'read-in-2010', '2016-books',\n",
    "    '2016-read', '2017-books-read', '2017-books-read', 'books-read-in-2016', '2016-books-read',\n",
    "\n",
    "    # 6. Meta or personal tags\n",
    "    'wishlist', 'wish-list', 'book-club', 'bookclub', 'book-club-books', 'book-club-reads',\n",
    "    'book-group', 'to-re-read', 're-read', 'reread', 'to-reread', 'to-read-owned', 'to-read-own',\n",
    "    'to-read-fiction', 'to-read-non-fiction', 'to-read-nonfiction', 'to-read-ya', 'to-read-series',\n",
    "    'to-read-classics', 'to-read-fantasy', 'to-review', 'to-purchase', 'to-be-read', 'to-be-released',\n",
    "    'to-read-soon', 'to-get', 'want-to-read', 'want-to-buy', 'want', 'need', 'need-to-buy',\n",
    "    'need-to-get', 'not-interested', 'maybe', 'maybe-read', 'recommendations', 'next', 'next-to-read',\n",
    "    'next-in-series', 'done', 'shelved', 'my-shelf', 'own-a-copy', 'own-tbr', 'top-tbr', 'not-for-me',\n",
    "    'considering', 'owned-but-not-read', 'wishlist', 'wishlist', 'owned-to-read'\n",
    "]\n",
    "\n",
    "\n",
    "blacklist_words = set(word.lower() for word in blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9301cf3-bcf0-4530-882b-62caf98d1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_cleaning = {\n",
    "    'cowboys': 'cowboy',\n",
    "    'chick lit': 'chick lit',\n",
    "    'adult fiction': 'adult fiction',\n",
    "    'cowboy western': 'cowboy western',\n",
    "    'genre western': 'western',\n",
    "    'romantic suspense': 'romantic suspense',\n",
    "    'action': 'action',\n",
    "    'series romance': 'romance',\n",
    "    'genre romance': 'romance',\n",
    "    'romance modern': 'modern romance',\n",
    "    'science fiction': 'science fiction',\n",
    "    'sci fi': 'science fiction',\n",
    "    'scifi': 'science fiction',\n",
    "    'post apocalyptic': 'post apocalyptic',\n",
    "    'sf': 'science fiction',\n",
    "    'sci fi fantasy': 'science fiction fantasy',\n",
    "    'dystopia': 'dystopian',\n",
    "    'apocalyptic': 'apocalyptic',\n",
    "    'science': 'science',\n",
    "    'speculative fiction': 'speculative fiction',\n",
    "    'fantasy sci fi': 'science fiction fantasy',\n",
    "    'apocalypse': 'apocalyptic',\n",
    "    'space opera': 'space opera',\n",
    "    'science fiction fantasy': 'science fiction fantasy',\n",
    "    'hard sci fi': 'hard science fiction',\n",
    "    'sff': 'science fiction fantasy',\n",
    "    'post apocalypse': 'post apocalyptic',\n",
    "    'sf fantasy': 'science fiction fantasy',\n",
    "    'sci fi and fantasy': 'science fiction fantasy',\n",
    "    'hard scifi': 'hard science fiction',\n",
    "    'sciencefiction': 'science fiction',\n",
    "    'regency romance': 'regency romance',\n",
    "    'romance historical': 'historical romance',\n",
    "    'mf': 'm f',\n",
    "    'historical romances': 'historical romance',\n",
    "    'historicals': 'historical',\n",
    "    'humorous': 'humor',\n",
    "    'humour': 'humor',\n",
    "    'humour comedy': 'humor',\n",
    "    'young adult': 'young adult',\n",
    "    'ya': 'young adult',\n",
    "    'fairies': 'fairies',\n",
    "    'faeries': 'fairies',\n",
    "    'faerie': 'fairies',\n",
    "    'fey': 'fae',\n",
    "    'ya fantasy': 'young adult fantasy',\n",
    "    'paranormal romance': 'paranormal romance',\n",
    "    'historical fantasy': 'historical fantasy',\n",
    "    'historical fic': 'historical fiction',\n",
    "    'supernatural': 'supernatural',\n",
    "    'faries': 'fairies',\n",
    "    'classic lit': 'classic literature',\n",
    "    'british lit': 'british literature',\n",
    "    'brit lit': 'british literature',\n",
    "    'english lit': 'english literature',\n",
    "    'lit': 'literature',\n",
    "    'feminist': 'feminism',\n",
    "    'ya books': 'young adult books',\n",
    "    'ya fiction': 'young adult fiction',\n",
    "    'ya': 'young adult',\n",
    "    'non fiction': 'nonfiction',\n",
    "    'non fic': 'nonfiction',\n",
    "    'distopian': 'dystopian',\n",
    "    'ya dystopian': 'young adult dystopian',\n",
    "    'ya lit': 'young adult literature'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb7349-f0bb-4a9c-bd44-2271f3445dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_cleaning.update({\n",
    "    'women s fiction': 'womens fiction',\n",
    "    'womens fiction': 'womens fiction', \n",
    "    'children s': 'children books',\n",
    "    'childrens books': 'children books',\n",
    "    'children s books': 'children books',\n",
    "    'children': 'children books',\n",
    "    'childrens': 'children books',\n",
    "    'kids books': 'children books',\n",
    "    'kid books': 'children books',\n",
    "    'general fiction': 'fiction',\n",
    "    'novels': 'novel',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a660d-c550-452a-886b-3346b50ccf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lcgft_config import lcgft_mapping\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Assuming genre_mapping and blacklist_words are defined\n",
    "\n",
    "def clean_name(name):\n",
    "    return name.lower().replace('-', ' ').replace('_', ' ').strip()\n",
    "\n",
    "def extract_shelves(shelves_str):\n",
    "    try:\n",
    "        shelves_list = ast.literal_eval(shelves_str)\n",
    "    except (SyntaxError, ValueError):\n",
    "        return []\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [(clean_name(shelf['name']), int(shelf.get('count', 0)))\n",
    "                for shelf in shelves_list if isinstance(shelf, dict) and 'name' in shelf]\n",
    "    return []\n",
    "\n",
    "def apply_cleaning_pipeline(shelves_str, shelf_cleaning, blacklist_words):\n",
    "    cleaned_tags_with_counts = defaultdict(int)\n",
    "    shelves = extract_shelves(shelves_str)\n",
    "    for tag, count in shelves:\n",
    "        mapped_tag = shelf_cleaning.get(tag, tag)\n",
    "        if not any(bad_word in mapped_tag for bad_word in blacklist_words):\n",
    "            cleaned_tags_with_counts[mapped_tag] += count\n",
    "    return sorted(cleaned_tags_with_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def extract_lcgft_and_tropes_from_cleaned(cleaned_shelves_series):\n",
    "    extracted_data = []\n",
    "    for shelf_tuples in cleaned_shelves_series:\n",
    "        lcgft_genres = []\n",
    "        trope_keywords = []\n",
    "        original_shelf = [item[0] for item in shelf_tuples]\n",
    "        for tag_tuple in shelf_tuples:\n",
    "            tag_name = tag_tuple[0]\n",
    "            if tag_name in lcgft_mapping:\n",
    "                lcgft_genres.append(lcgft_mapping[tag_name])\n",
    "            else:\n",
    "                trope_keywords.append(tag_name)\n",
    "        extracted_data.append({'shelf': original_shelf, 'lcgft_genres': list(set(lcgft_genres)), 'trope_keywords': list(set(trope_keywords))})\n",
    "    return extracted_data\n",
    "\n",
    "sample_1star['cleaned_shelves'] = sample_1star['popular_shelves'].apply(\n",
    "    apply_cleaning_pipeline,\n",
    "    args=(shelf_cleaning, blacklist_words)\n",
    ")\n",
    "\n",
    "shelf_results = extract_lcgft_and_tropes_from_cleaned(sample_1star['cleaned_shelves'])\n",
    "print(shelf_results[:5]) # Print the first few results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6a66c-400f-40c0-a787-019e065044cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lcgft_config import lcgft_mapping\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Assuming genre_mapping and blacklist_words are defined\n",
    "\n",
    "def clean_name(name):\n",
    "    return name.lower().replace('-', ' ').replace('_', ' ').strip()\n",
    "\n",
    "def extract_shelves(shelves_str):\n",
    "    try:\n",
    "        shelves_list = ast.literal_eval(shelves_str)\n",
    "    except (SyntaxError, ValueError):\n",
    "        return []\n",
    "    if isinstance(shelves_list, list):\n",
    "        return [(clean_name(shelf['name']), int(shelf.get('count', 0)))\n",
    "                for shelf in shelves_list if isinstance(shelf, dict) and 'name' in shelf]\n",
    "    return []\n",
    "\n",
    "def apply_cleaning_pipeline(shelves_str, shelf_cleaning, blacklist_words):\n",
    "    cleaned_tags_with_counts = defaultdict(int)\n",
    "    shelves = extract_shelves(shelves_str)\n",
    "    for tag, count in shelves:\n",
    "        mapped_tag = shelf_cleaning.get(tag, tag)\n",
    "        if not any(bad_word in mapped_tag for bad_word in blacklist_words):\n",
    "            cleaned_tags_with_counts[mapped_tag] += count\n",
    "    return sorted(cleaned_tags_with_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def extract_lcgft_and_tropes(shelves_str, blacklist): # Pass blacklist as argument\n",
    "    cleaned_shelves = apply_cleaning_pipeline(shelves_str, shelf_cleaning, blacklist)\n",
    "    lcgft_genres = set()\n",
    "    trope_keywords = set()\n",
    "    original_shelf = [item[0] for item in cleaned_shelves]\n",
    "    for tag_tuple in cleaned_shelves:\n",
    "        tag_name = tag_tuple[0]\n",
    "        if tag_name in lcgft_mapping:\n",
    "            lcgft_genres.add(lcgft_mapping[tag_name])\n",
    "        elif not any(bad_word in tag_name for bad_word in blacklist): # Apply blacklist here too\n",
    "            trope_keywords.add(tag_name)\n",
    "    return pd.Series({'original_shelf': list(original_shelf), 'lcgft_genres': list(lcgft_genres), 'trope_keywords': list(trope_keywords)})\n",
    "\n",
    "# Assuming sample_1star is your DataFrame and 'popular_shelves' is the column\n",
    "shelf_results_df = sample_1star['popular_shelves'].apply(extract_lcgft_and_tropes, args=(blacklist_words,))\n",
    "\n",
    "# Assign the columns directly\n",
    "sample_1star['original_shelf'] = shelf_results_df['original_shelf']\n",
    "sample_1star['lcgft_genres'] = shelf_results_df['lcgft_genres']\n",
    "sample_1star['trope_keywords'] = shelf_results_df['trope_keywords']\n",
    "\n",
    "# Now your DataFrame 'sample_1star' will have the updated columns with the blacklist applied to tropes\n",
    "print(sample_1star[['popular_shelves', 'original_shelf', 'lcgft_genres', 'trope_keywords']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258367c7-c30d-4926-861a-043b09fd8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_trope_list(trope_list): #double cleaning\n",
    "    cleaned_tropes = []\n",
    "    if isinstance(trope_list, list):\n",
    "        for trope in trope_list:\n",
    "            cleaned_trope = trope.lower().strip()\n",
    "            if cleaned_trope and cleaned_trope not in ['a', 'the', 'of', 'and', 'in']: # Example stop words\n",
    "                cleaned_tropes.append(cleaned_trope)\n",
    "    return list(set(cleaned_tropes)) # Remove duplicates after cleaning\n",
    "\n",
    "sample_1star['cleaned_tropes'] = sample_1star['trope_keywords'].apply(clean_trope_list)\n",
    "print(sample_1star[['trope_keywords', 'cleaned_tropes']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262d2a2-c523-4c18-b0ba-345f428f23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_1star['popular_shelves'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549b518-2b9f-482f-a4ad-60ad9a765034",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943283a9-37c8-4b6d-a8f7-6266a54ee4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and count\n",
    "shelf_counts = Counter(chain.from_iterable(\n",
    "    [shelf for shelf, _ in row] for row in sample_1star['cleaned_shelves']\n",
    "))\n",
    "\n",
    "# Get top N shelves\n",
    "top_shelves = shelf_counts.most_common(20)\n",
    "shelf_names, counts = zip(*top_shelves)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(shelf_names, counts, color='mediumseagreen')\n",
    "plt.xlabel(\"Number of Reviews\")\n",
    "plt.title(\"Most Common Shelves in 1-Star Reviews\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add labels\n",
    "for bar, count in zip(bars, counts):\n",
    "    plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "             str(count), va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Most Common Shelves in 1-Star Reviews', format='jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94506187-a4f3-4152-95c1-d4019d21fc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8012c1a-9cb5-4440-b54e-232e4fade5ad",
   "metadata": {},
   "source": [
    "## sentiment analysis - currently iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffd1e9-f8c7-4284-9ca4-eb1cd777006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all descriptions\n",
    "all_descriptions = ' '.join(sample_1star['description_clean'].dropna())\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width=1000, height=500, background_color='white',\n",
    "                      max_words=100, colormap='viridis').generate(all_descriptions)\n",
    "\n",
    "# Display it\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Common Words in Book Descriptions', fontsize=16)\n",
    "plt.show()\n",
    "plt.savefig('Common Words in Book Descriptions', format='jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3542cc-0a34-4f64-bd85-46a2456c5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0e8a5-bc5c-4e34-88e1-6abca130838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4cfe69-69e9-4d5e-b448-270045865250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    if pd.isnull(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return None\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity  # Returns a float from -1 (negative) to 1 (positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e5e0a-888e-4ced-b7fe-bba7ec457708",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star['desc_sentiment'] = sample_1star['description_clean'].apply(get_sentiment)\n",
    "sample_1star['review_sentiment'] = sample_1star['review_clean'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479efedb-1531-45e4-8f29-60d0404cf71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(sample_1star['review_sentiment'], bins=30, kde=True, color='tomato')\n",
    "plt.title(\"Sentiment Distribution of 1-Star Reviews\")\n",
    "plt.xlabel(\"Review Sentiment Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axvline(0, linestyle='--', color='gray', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Sentiment Distribution of 1-Star Reviews', format='jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcc6e6-76c4-4283-ac90-102d80f8712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(sample_1star['desc_sentiment'], bins=30, kde=True, color='steelblue')\n",
    "plt.title(\"Sentiment Distribution of Book Descriptions\")\n",
    "plt.xlabel(\"Description Sentiment Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axvline(0, linestyle='--', color='gray', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Sentiment Distribution of Book Descriptions', format='jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a5fea-e6c8-47c2-9464-a428b70889e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sentiment agreement/contradiction\n",
    "def sentiment_relationship(row):\n",
    "    if row['desc_sentiment'] >= 0 and row['review_sentiment'] < 0:\n",
    "        return 'Positive Blurb / Negative Review'\n",
    "    elif row['desc_sentiment'] < 0 and row['review_sentiment'] >= 0:\n",
    "        return 'Negative Blurb / Positive Review'\n",
    "    elif row['desc_sentiment'] >= 0 and row['review_sentiment'] >= 0:\n",
    "        return 'Both Positive'\n",
    "    else:\n",
    "        return 'Both Negative'\n",
    "\n",
    "# Apply this relationship to the DataFrame\n",
    "sample_1star['sentiment_relation'] = sample_1star.apply(sentiment_relationship, axis=1)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=sample_1star,\n",
    "    x='desc_sentiment',\n",
    "    y='review_sentiment',\n",
    "    hue='sentiment_relation',\n",
    "    alpha=0.5,\n",
    "    palette={\n",
    "        'Positive Blurb / Negative Review': '#e74c3c',\n",
    "        'Negative Blurb / Positive Review': '#9b59b6',\n",
    "        'Both Positive': '#27ae60',\n",
    "        'Both Negative': '#3498db'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add vertical and horizontal lines at zero\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.axvline(0, color='gray', linestyle='--')\n",
    "\n",
    "# Annotations for quadrants\n",
    "plt.text(0.55, -0.9, 'Positive Description\\nNegative Review', color='#e74c3c', fontsize=10, weight='bold')\n",
    "plt.text(-0.9, 0.8, 'Negative Description\\nPositive Review', color='#9b59b6', fontsize=10, weight='bold')\n",
    "plt.text(0.5, 0.75, 'Both Positive', color='#27ae60', fontsize=10, weight='bold')\n",
    "plt.text(-0.8, -0.8, 'Both Negative', color='#3498db', fontsize=10, weight='bold')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Description Sentiment\", fontsize=12)\n",
    "plt.ylabel(\"Review Sentiment\", fontsize=12)\n",
    "plt.title(\"Do 1-Star Reviews Contradict Book Descriptions?\", fontsize=14, weight='bold')\n",
    "plt.legend(title='Sentiment Match', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Do 1-Star Reviews Contradict Book Descriptions?', format='jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d73205-fc4c-49e1-b261-5fe8ec2087d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as a contradiction if description is positive but review is strongly negative\n",
    "sample_1star['contradiction'] = sample_1star.apply(\n",
    "    lambda row: row['desc_sentiment'] > 0.2 and row['review_sentiment'] < -0.2,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show proportion and example titles\n",
    "contradict_pct = sample_1star['contradiction'].mean() * 100\n",
    "print(f\"{contradict_pct:.2f}% of 1-star reviews contradict the description's positive tone\")\n",
    "\n",
    "# Optionally preview top contradicting cases\n",
    "sample_1star[sample_1star['contradiction'] == True][['title', 'desc_sentiment', 'review_sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b7989-6aaf-47f5-a0e9-595d524bd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of books per sentiment relationship\n",
    "sentiment_counts = sample_1star['sentiment_relation'].value_counts().reset_index()\n",
    "sentiment_counts.columns = ['Sentiment Relationship', 'Count']\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.barh(\n",
    "    sentiment_counts['Sentiment Relationship'],\n",
    "    sentiment_counts['Count'],\n",
    "    color=['#e74c3c', '#9b59b6', '#27ae60', '#3498db']\n",
    " )\n",
    "\n",
    "# Add count labels next to bars\n",
    "for bar in bars:\n",
    "    plt.text(\n",
    "        bar.get_width() + 100,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{int(bar.get_width())}\",\n",
    "        va='center',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "# Title and labels\n",
    "plt.xlabel(\"Number of Books\")\n",
    "plt.title(\"How Often Do Review & Description Sentiments Match?\", fontsize=13, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('How Often Do Review & Description Sentiments Match?', format='jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac1016-761f-4804-acf7-232690b5e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1star.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d800ae8e-4823-45d7-8c79-84b2d418d69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bd65e-1b2f-4ea9-887d-c551399b1df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
